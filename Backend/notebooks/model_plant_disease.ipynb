{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c6248e0",
   "metadata": {},
   "source": [
    "### Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad7da76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import kagglehub\n",
    "from matplotlib.image import imread\n",
    "import cv2\n",
    "import random\n",
    "import os\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from tensorflow. keras.utils import img_to_array, array_to_img\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Flatten, Dense\n",
    "from sklearn. model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c392e50",
   "metadata": {},
   "source": [
    "### Defining the path of dataset directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c517e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = kagglehub.dataset_download(\"vipoooool/new-plant-diseases-dataset\")\n",
    "\n",
    "path = os.path.join(dataset_path, \"New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0093c852",
   "metadata": {},
   "source": [
    "### Visualizing the images and Resize images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08e6cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting 12 images to check dataset\n",
    "\n",
    "plt.figure(figsize = (12, 12))\n",
    "\n",
    "folders = os.listdir(path)\n",
    "selected_images = []\n",
    "\n",
    "# Select two images from each of the first 6 directories\n",
    "for folder in folders[:6]:\n",
    "    folder_path = os.path.join(path, folder)\n",
    "    if os.path.isdir(folder_path):\n",
    "        images = os.listdir(folder_path)\n",
    "        selected_images.extend([os.path.join(folder_path, img) for img in random.sample(images, min(2, len(images)))])\n",
    "\n",
    "# Plot the selected images\n",
    "for i, img_path in enumerate(selected_images, 1):\n",
    "    plt.subplot(4, 3, i)\n",
    "    plt.tight_layout()\n",
    "    rand_img = Image.open(img_path)\n",
    "    plt.imshow(rand_img)\n",
    "    plt.xlabel(rand_img.size[0], fontsize=10)  # width of image\n",
    "    plt.ylabel(rand_img.size[1], fontsize=10)  # height of image\n",
    "    folder_name = os.path.basename(os.path.dirname(img_path))\n",
    "    plt.title(folder_name, fontsize=8)  # Add folder name as label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72acdfe6",
   "metadata": {},
   "source": [
    "### Convert the images into a Numpy array and normalize them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514123d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_image_to_array(image_dir):\n",
    "    try:\n",
    "        image = cv2.imread(image_dir)\n",
    "        if image is not None :\n",
    "            image = Image.open(image_dir).convert('RGB')\n",
    "            return img_to_array(image)\n",
    "        else :\n",
    "            return np.array([])\n",
    "    except Exception as e:\n",
    "        print(f\"Error : {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ae615c",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list, label_list = [], []\n",
    "labels = ['Tomato___Septoria_leaf_spot','Tomato___Tomato_Yellow_Leaf_Curl_Virus', 'Tomato___healthy']\n",
    "binary_labels = [i for i in range(len(labels))]\n",
    "\n",
    "# Reading and converting image to numpy array\n",
    "\n",
    "for i, label in enumerate(labels):\n",
    "    plant_image_list = os.listdir(f\"{path}/{label}\")\n",
    "    for file in plant_image_list:\n",
    "        image_path = f\"{path}/{label}/{file}\"\n",
    "        image_list.append(convert_image_to_array(image_path))\n",
    "        label_list.append(binary_labels[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4342c08",
   "metadata": {},
   "source": [
    "### Visualize the class count and Check for class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b76840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the number of classes count\n",
    "\n",
    "label_counts = pd.DataFrame(label_list).value_counts()\n",
    "label_counts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff746166",
   "metadata": {},
   "source": [
    "It is a balanced dataset as we can see, let's observe the shape of the images now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e275c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856909c1",
   "metadata": {},
   "source": [
    "### Splitting the dataset into train, validate and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94cd8d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(image_list, label_list, test_size=0.2, random_state = 10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d5efa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will normalize the dataset of our images. As pixel values ranges from 0 to 255 so we will divide each image pixel with 255 to normalize the dataset.\n",
    "\n",
    "x_train = np.array(x_train, dtype=np.float16) / 225.0\n",
    "x_test = np.array(x_test, dtype=np.float16) / 225.0\n",
    "x_train = x_train.reshape(-1, 256, 256, 3)\n",
    "x_test = x_test.reshape(-1, 256, 256, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc6dd56",
   "metadata": {},
   "source": [
    "### Performing one-hot encoding on target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad404a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2993fa04",
   "metadata": {},
   "source": [
    "### Creating the model architecture, compile the model and then fit it using the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebad6064",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding = \"same\",input_shape = (256, 256, 3), activation = \"relu\"))\n",
    "model.add(MaxPooling2D(pool_size = (3, 3)))\n",
    "model.add(Conv2D(16, (3, 3), padding = \"same\", activation = \"relu\"))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(8, activation = \"relu\"))\n",
    "model.add(Dense(3, activation = \"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8e986e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'categorical_crossentropy', optimizer = Adam(0.0001), metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33850f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the training data set into training and validation data sets\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size = 0.2, random_state = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e22afc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "\n",
    "epochs = 50\n",
    "batch_size = 128\n",
    "history = model.fit(x_train, y_train, batch_size = batch_size, epochs = epochs, validation_data = (x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82514d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"../models/plant_disease_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223cd4a8",
   "metadata": {},
   "source": [
    "### Plot the accuracy and loss against each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ba7a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training history\n",
    "\n",
    "plt.figure(figsize = (12, 5))\n",
    "plt.plot(history.history['accuracy'], color = 'r')\n",
    "plt.plot(history.history['val_accuracy'], color = 'b')\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(['train', 'val'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6869568",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Calculating model accuracy\")\n",
    "\n",
    "scores = model.evaluate(x_test, y_test)\n",
    "print(f\"Test Accuracy: {scores[1] * 100}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e8494f",
   "metadata": {},
   "source": [
    "### Make predictions on testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cde775",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a8ce65",
   "metadata": {},
   "source": [
    "### Visualizing the original and predicted labels for the test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4596256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting image to compare\n",
    "\n",
    "img = array_to_img(x_test[11])\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5235c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding max value from predition list and comaparing original value vs predicted\n",
    "\n",
    "print(\"Originally : \", labels[np.argmax(y_test[11])])\n",
    "print(\"Predicted : \", labels[np.argmax(y_pred[4])])\n",
    "print(y_pred[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c41307",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = np.sum(np.argmax(y_pred, axis=1) == np.argmax(y_test, axis=1))\n",
    "\n",
    "print(f\"Number of matches: {(matches/len(y_test))*100}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
